## 加和值 平均值 标准差
## 加权均值

## 众数 中位数

## 欧氏距离

## 曼哈顿距离

## 同比和环比

## 抽样

## 正态分布（高斯分布）

## 泊松分布

## 伯努利分布


## 信息量
  信息量 I = log2m
  H(x) = -log2P (P:先验概率)
## 香农公式

## 热力熵

## 信息熵
  H(x)求和
  信息越确定，越单一，信息熵越小
  信息越不确定 越混乱，信息熵越大
